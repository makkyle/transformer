{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c58b1ad-04f5-48c8-a6b4-7bb87588a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import difflib\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c575f14-d03d-481b-9ef8-23f13a0eaf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('CM_d1.xlsx', sheet_name='Table S1')\n",
    "# print(df)\n",
    "df = df[[\"Patient ID\",\"Binds to\", \"Protein + Epitope\",\"CDRH3\", \"CDRL3\"]]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7cbf0e-eef8-458b-96d7-bcf64f77b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "## 1) split the viral strains by the separator and duplicate them \n",
    "\n",
    "for i in range(len(df[\"Binds to\"])):\n",
    "    if \",\" in df[\"Binds to\"][i]:\n",
    "        concat_list = df[\"Binds to\"][i]\n",
    "        print(concat_list)\n",
    "        f_list = concat_list.split(',')\n",
    "        print(f_list)\n",
    "        print(len(f_list))\n",
    "        print(i)\n",
    "        ## rename the current row with the first viral strain name\n",
    "        df[\"Binds to\"][i] = f_list[0]\n",
    "        \n",
    "        ## Specify the row index to copy\n",
    "        row_to_copy = i\n",
    "        # Number of times to replicate the row\n",
    "        replication_factor = len(f_list) -1 \n",
    "        # Use numpy to replicate the selected row\n",
    "        replicated_rows = np.tile(df.loc[row_to_copy].values, (replication_factor, 1))\n",
    "        # Create a new DataFrame from the replicated rows\n",
    "        new_rows_df = pd.DataFrame(replicated_rows, columns=df.columns)\n",
    "        print(new_rows_df)\n",
    "        if replication_factor == 1:\n",
    "            new_rows_df[\"Binds to\"][0] =  f_list[1]\n",
    "        elif replication_factor == 2:\n",
    "            new_rows_df[\"Binds to\"][0] =  f_list[1]\n",
    "            new_rows_df[\"Binds to\"][1] =  f_list[2]\n",
    "        elif replication_factor == 3:\n",
    "            new_rows_df[\"Binds to\"][0] =  f_list[1]\n",
    "            new_rows_df[\"Binds to\"][1] =  f_list[2]\n",
    "            new_rows_df[\"Binds to\"][2] =  f_list[3]\n",
    "        elif replication_factor == 4:\n",
    "            new_rows_df[\"Binds to\"][0] =  f_list[1]\n",
    "            new_rows_df[\"Binds to\"][1] =  f_list[2]\n",
    "            new_rows_df[\"Binds to\"][2] =  f_list[3]\n",
    "            new_rows_df[\"Binds to\"][3] =  f_list[4]\n",
    "        elif replication_factor == 5:\n",
    "            new_rows_df[\"Binds to\"][0] =  f_list[1]\n",
    "            new_rows_df[\"Binds to\"][1] =  f_list[2]\n",
    "            new_rows_df[\"Binds to\"][2] =  f_list[3]\n",
    "            new_rows_df[\"Binds to\"][3] =  f_list[4]\n",
    "            new_rows_df[\"Binds to\"][4] =  f_list[5]\n",
    "        elif replication_factor == 6:\n",
    "            new_rows_df[\"Binds to\"][0] =  f_list[1]\n",
    "            new_rows_df[\"Binds to\"][1] =  f_list[2]\n",
    "            new_rows_df[\"Binds to\"][2] =  f_list[3]\n",
    "            new_rows_df[\"Binds to\"][3] =  f_list[4]\n",
    "            new_rows_df[\"Binds to\"][4] =  f_list[5]\n",
    "            new_rows_df[\"Binds to\"][5] =  f_list[6]\n",
    "        elif replication_factor == 7:\n",
    "            new_rows_df[\"Binds to\"][0] =  f_list[1]\n",
    "            new_rows_df[\"Binds to\"][1] =  f_list[2]\n",
    "            new_rows_df[\"Binds to\"][2] =  f_list[3]\n",
    "            new_rows_df[\"Binds to\"][3] =  f_list[4]\n",
    "            new_rows_df[\"Binds to\"][4] =  f_list[5]\n",
    "            new_rows_df[\"Binds to\"][5] =  f_list[6]\n",
    "            new_rows_df[\"Binds to\"][6] =  f_list[7]\n",
    "        elif replication_factor == 8:\n",
    "            new_rows_df[\"Binds to\"][0] =  f_list[1]\n",
    "            new_rows_df[\"Binds to\"][1] =  f_list[2]\n",
    "            new_rows_df[\"Binds to\"][2] =  f_list[3]\n",
    "            new_rows_df[\"Binds to\"][3] =  f_list[4]\n",
    "            new_rows_df[\"Binds to\"][4] =  f_list[5]\n",
    "            new_rows_df[\"Binds to\"][5] =  f_list[6]\n",
    "            new_rows_df[\"Binds to\"][6] =  f_list[7]\n",
    "            new_rows_df[\"Binds to\"][7] =  f_list[8]\n",
    "        elif replication_factor == 9:\n",
    "            new_rows_df[\"Binds to\"][0] =  f_list[1]\n",
    "            new_rows_df[\"Binds to\"][1] =  f_list[2]\n",
    "            new_rows_df[\"Binds to\"][2] =  f_list[3]\n",
    "            new_rows_df[\"Binds to\"][3] =  f_list[4]\n",
    "            new_rows_df[\"Binds to\"][4] =  f_list[5]\n",
    "            new_rows_df[\"Binds to\"][5] =  f_list[6]\n",
    "            new_rows_df[\"Binds to\"][6] =  f_list[7]\n",
    "            new_rows_df[\"Binds to\"][7] =  f_list[8]\n",
    "            new_rows_df[\"Binds to\"][8] =  f_list[9]\n",
    "\n",
    "        \n",
    "        # Append the new rows to the original DataFrame\n",
    "        df = df._append(new_rows_df, ignore_index=True)\n",
    "        print(df.tail(10))\n",
    "        # time.sleep(5)\n",
    "        \n",
    "    else:\n",
    "        print(\"single entry\")\n",
    "        \n",
    "print(df)\n",
    "# df.to_csv(\"filtered_df_binds_to.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf54da2-d0ea-4862-a43b-8fa9a04e620c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df)\n",
    "df.to_csv(\"filtered_df_binds_to.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2fbb0-9537-4ebc-8e28-a329aeca8f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from random import sample \n",
    "df = pd.read_csv(\"filtered_df_binds_to.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b31239-e35e-42f4-bd96-06e498b146c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 2) sort the column \"Binds to\"\n",
    "df = df.sort_values(by = ['Binds to'])\n",
    "df = df.reset_index()\n",
    "df = df.drop([\"index\"],axis=1)\n",
    "print(df)\n",
    "print(df[\"Binds to\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e8faae-d41f-44d5-9c8b-f64b09dd5473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"labels\"] = 0\n",
    "print(df)\n",
    "\n",
    "num = 0\n",
    "\n",
    "for i in range(len(df[\"Binds to\"])):\n",
    "    if df[\"Binds to\"][i] == \"SARS-CoV-2\":\n",
    "        df[\"labels\"][i] = num \n",
    "    elif df[\"Binds to\"][i] == \"SARS-CoV\":\n",
    "        df[\"labels\"][i] = num+1\n",
    "    elif df[\"Binds to\"][i] == \"229E\":\n",
    "        df[\"labels\"][i] = num+2\n",
    "    elif df[\"Binds to\"][i] == \"HKU1\":\n",
    "        df[\"labels\"][i] = num+3\n",
    "    elif df[\"Binds to\"][i] == \"OC43\":\n",
    "        df[\"labels\"][i] = num+4\n",
    "    elif df[\"Binds to\"][i] == \"OV43\":\n",
    "        df[\"labels\"][i] = num+5\n",
    "    elif df[\"Binds to\"][i] == \"MERS-CoV\":\n",
    "        df[\"labels\"][i] = num+6\n",
    "    elif df[\"Binds to\"][i] == \"NL63\":\n",
    "        df[\"labels\"][i] = num+7\n",
    "    elif df[\"Binds to\"][i] == \"HKU\":\n",
    "        df[\"labels\"][i] = num+8\n",
    "# print(df)\n",
    "\n",
    "# df.to_csv(\"filtered_df_binds_to.csv\")\n",
    "print(df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bbb0b1-8767-4f7e-be99-85c90e10a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample \n",
    "## 1) locate the positions of the rows for each viral strain (listed in index_name)\n",
    "index_list = []\n",
    "index_name = ['SARS-CoV-2','SARS-CoV','229E', 'HKU1','OC43','NL63']\n",
    "\n",
    "for i in range(len(index_name)):\n",
    "    index_no = df.loc[(df == index_name[i]).any(axis=1)].index\n",
    "    # print(index_no)\n",
    "    index_list.append(index_no)\n",
    "\n",
    "# print(index_list)\n",
    "# print(index_no[0])\n",
    "# print(index_no[-1])\n",
    "\n",
    "## 2) shuffle and sample generator\n",
    "\n",
    "for i in range(len(index_list)):\n",
    "    if len(index_list[i]) >= 50:\n",
    "        index_list[i] = index_list[i].tolist()\n",
    "        random.shuffle(index_list[i])\n",
    "        index_list[i] = sample(index_list[i],50)\n",
    "    elif len(index_list[i]) <50:\n",
    "        index_list[i] = index_list[i].tolist()\n",
    "print(index_list)\n",
    "print(type(index_list))\n",
    "# index_arr = np.array(index_list)\n",
    "# print(index_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6c4fb-4eae-4369-9fa8-bfa37eed03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# index_list = index_list[0] + index_list[1] + index_list[2] + index_list[3]\n",
    "print(type(index_list[0]))\n",
    "print(index_list[0])\n",
    "\n",
    "## 3) Merge all the lists within the list into a list \n",
    "# merged_list = itertools.chain.from_iterable(index_list)\n",
    "merge_list = index_list[0] + index_list[1] + index_list[2] + index_list[3] + index_list[4] + index_list[5]\n",
    "print(merge_list)\n",
    "print(len(merge_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebdcfd0-198c-4f4a-8656-dd7b7eb873ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4) form a new df based on the list of indices with the 4 columns (Binds to, CDRH3, CDRL3, labels)\n",
    "\n",
    "new_df= df.filter(items = merge_list, axis=0)\n",
    "new_df = new_df.reset_index()\n",
    "# print(new_df)\n",
    "# print(new_df['Binds to'].value_counts())\n",
    "        \n",
    "\n",
    "# SARS-CoV-2    50\n",
    "# SARS-CoV      50\n",
    "# 229E          50\n",
    "# HKU1          50\n",
    "# OC43          49\n",
    "# NL63          47\n",
    "\n",
    "## 4b) remove the 'labels' column and replace it with a new 'labels' column\n",
    "new_df = new_df.drop('labels', axis=1)\n",
    "# print(new_df)\n",
    "\n",
    "new_df[\"labels\"] = 0\n",
    "# print(new_df)\n",
    "\n",
    "num = 0\n",
    "\n",
    "for i in range(len(new_df[\"Binds to\"])):\n",
    "    if new_df[\"Binds to\"][i] == \"SARS-CoV-2\":\n",
    "        new_df[\"labels\"][i] = num \n",
    "    elif new_df[\"Binds to\"][i] == \"SARS-CoV\":\n",
    "        new_df[\"labels\"][i] = num+1\n",
    "    elif new_df[\"Binds to\"][i] == \"229E\":\n",
    "        new_df[\"labels\"][i] = num+2\n",
    "    elif new_df[\"Binds to\"][i] == \"HKU1\":\n",
    "        new_df[\"labels\"][i] = num+3\n",
    "    elif new_df[\"Binds to\"][i] == \"OC43\":\n",
    "        new_df[\"labels\"][i] = num+4\n",
    "    elif new_df[\"Binds to\"][i] == \"NL63\":\n",
    "        new_df[\"labels\"][i] = num+5\n",
    "\n",
    "print(new_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246cd2fd-240f-4986-8f30-f5f81d9c614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('even_data_df_6_classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3f4199-3368-4330-b5ae-1446cd732dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(\"even_data_df_6_classes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12beb31a-9641-4158-b35d-56ff2745a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## before proceeding to one-hot encoding, \n",
    "## remove any rows with NaN \n",
    "\n",
    "new_df.dropna(subset=['CDRH3'], inplace=True)\n",
    "new_df.dropna(subset=['CDRL3'], inplace=True)\n",
    "\n",
    "## final : one-hot encoding for CDRH3 and CDRL3\n",
    "CDRH3=new_df[\"CDRH3\"]\n",
    "CDRL3=new_df[\"CDRL3\"]\n",
    "\n",
    "\n",
    "ALPHABET=\"ACDEFGHIKLMNPQRSTVWY\"\n",
    "MAX_LENGTH_INPUT=40\n",
    "def one_hot_encoder(s,  alphabet=ALPHABET):\n",
    "    # Build dictionary\n",
    "    \n",
    "    d = {a: i for i, a in enumerate(alphabet)}\n",
    "\n",
    "    # Encode\n",
    "    \n",
    "    # x = np.zeros((len(s), len(d)+1))\n",
    "    x = np.zeros((MAX_LENGTH_INPUT, len(d)+1))\n",
    "    x[range(len(s)),[d[c] if c in alphabet else len(d) for c in s]] = 1\n",
    "    if any(x[:,len(d)]>0):\n",
    "        # print(s)\n",
    "        kk=0\n",
    "\n",
    "    \n",
    "    return x[:,:len(d)]\n",
    "\n",
    "# def sequence2onehot(seqs):\n",
    "#     str_rep=''\n",
    "#     seq_length=300\n",
    "#     # seq_max_length=0\n",
    "#     seq_vecs=[]\n",
    "#     for j, seq in enumerate(seqs):\n",
    "#         seq = seq.replace(' ', str_rep)\n",
    "#         seq = seq.replace('\\n', str_rep)\n",
    "#         seq = seq.replace('\\t', str_rep)\n",
    "#         seq = seq.replace('_', str_rep)\n",
    "#         seq_v = np.zeros([seq_length, 20])\n",
    "#         seq_v[0:len(seq), :] = one_hot_encoder(s=seq)\n",
    "#         # seq_vecs.append([seq_v, seq_length - len(seq), len(seq)])\n",
    "#         # seq_max_length = max(seq_max_length, len(seq))\n",
    "#     return seq_vecs\n",
    "\n",
    "max_len=0\n",
    "seq_h_list=[]\n",
    "seq_l_list=[]\n",
    "for i in range(len(CDRH3)):\n",
    "    seq=CDRH3.iloc[i]\n",
    "\n",
    "    if isinstance(seq, str):\n",
    "        seq_list=list(seq)\n",
    "        seq_e=one_hot_encoder(seq_list)\n",
    "        # print(seq_e.shape)\n",
    "        lenl=len(seq_list)\n",
    "        if lenl>max_len:\n",
    "            max_len=lenl\n",
    "        seq_h_list.append(seq_e)\n",
    "    else:\n",
    "        print('nan')\n",
    "        \n",
    "        # seq_e= np.zeros((MAX_LENGTH_INPUT, 20)) \n",
    "        # seq_h_list.append(seq_e)\n",
    "for i in range(len(CDRL3)):\n",
    "    seq=CDRH3.iloc[i]\n",
    "\n",
    "    if isinstance(seq, str):\n",
    "        seq_list=list(seq)\n",
    "        seq_e=one_hot_encoder(seq_list)\n",
    "        # print(seq_e.shape)\n",
    "        lenl=len(seq_list)\n",
    "        if lenl>max_len:\n",
    "            max_len=lenl\n",
    "        seq_l_list.append(seq_e)\n",
    "    else:\n",
    "        print('nan')\n",
    "        # seq_e= np.zeros((MAX_LENGTH_INPUT, 20)) \n",
    "        # seq_l_list.append(seq_e)\n",
    "print(max_len)\n",
    "\n",
    "seq_h_arr=np.array(seq_h_list)\n",
    "seq_l_arr=np.array(seq_l_list)\n",
    "\n",
    "print(seq_h_arr.shape,np.max(seq_h_arr),np.min(seq_h_arr))\n",
    "print(seq_l_arr.shape,np.max(seq_l_arr),np.min(seq_l_arr))\n",
    "\n",
    "np.save('./high_seq.npy',seq_h_arr)\n",
    "np.save('./low_seq.npy',seq_l_arr)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a2f359-e149-4975-9994-5e7469af8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "## final : one-hot encoding for labels \n",
    "# labels_list = df[\"labels\"]\n",
    "\n",
    "# print(type(labels_list))\n",
    "\n",
    "df_copy = new_df.copy()\n",
    "print(df_copy)\n",
    "\n",
    "# df_encoded = pd.get_dummies(df_copy, columns=['Binds to',], dtype=int)\n",
    "# print(df_encoded)\n",
    "\n",
    "def convert_to_one_hot(labels, num_classes):\n",
    "    #计算向量有多少行\n",
    "    num_labels = len(labels)\n",
    "    #生成值全为0的独热编码的矩阵\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    #计算向量中每个类别值在最终生成的矩阵“压扁”后的向量里的位置\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    #遍历矩阵，为每个类别的位置填充1\n",
    "    labels_one_hot.flat[index_offset + labels] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "\n",
    "labels = df_copy[\"labels\"]\n",
    "print(type(labels))\n",
    "labels = labels.tolist()\n",
    "print(convert_to_one_hot(labels,6))\n",
    "one_hot_labels = convert_to_one_hot(labels,6)\n",
    "print(one_hot_labels.shape)\n",
    "np.save(\"Y_labels_binds_to.npy\",one_hot_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f78b710-a954-4c49-8a41-243d1f94c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Y_labels_binds_to.npy\",one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a3ae20-ae01-43c1-927e-61479d311c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9904f694-f98a-41e2-b976-87a7d2695441",
   "metadata": {},
   "outputs": [],
   "source": [
    "## logomaker plot generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e52ac89-1bda-4e22-a478-87fa6e2442b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harol\\AppData\\Local\\Temp\\ipykernel_7932\\3502252306.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_excel('CM_d1.xlsx', sheet_name='Table S1')\n",
    "df = df[[\"Patient ID\",\"Binds to\", \"Protein + Epitope\",\"CDRH3\", \"CDRL3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fc31a0-e856-4c90-818e-26707fe74fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3) Measure the 80% similarity score for each viral strain class \n",
    "## 3a) find the index_no for certain class of antigen_name column\n",
    "\n",
    "\n",
    "index_no = df.loc[(df == 'SARS-CoV-2').any(axis=1)].index\n",
    "print(index_no)\n",
    "\n",
    "print(index_no[0])\n",
    "print(index_no[-1])\n",
    "\n",
    "# 3b) fit in the index_no into the range in which the for loop will run\n",
    "# import time\n",
    "# import difflib\n",
    "\n",
    "# index_list_ = index_no\n",
    "\n",
    "# good_list = []\n",
    "# index = 0 \n",
    "\n",
    "# # def similarity_80_calculator(x,y):\n",
    "    \n",
    "        \n",
    "# for i in range(len(index_list_0)):\n",
    "#     for j in range(len(index_list_0)):\n",
    "#         # print(index_list_0[i],index_list_0[j])\n",
    "#         x = index_list_0[i]\n",
    "#         y = index_list_0[j]\n",
    "#         index += 1 \n",
    "#         print(index)\n",
    "#         try:\n",
    "#             a = df[\"CDRH3\"][x]\n",
    "#             b = df[\"CDRH3\"][y]\n",
    "#             seq=difflib.SequenceMatcher(None,a ,b)\n",
    "#             d=seq.ratio()*100\n",
    "#             # d = int(d)\n",
    "#             if d > 80:\n",
    "#                 good_list.append(a)\n",
    "#                 good_list.append(b)\n",
    "#                 print(d)\n",
    "#                 print(\"appending to list\")\n",
    "#                 print(a,b)\n",
    "#             else:\n",
    "#                 print(\"not appended\")\n",
    "#             # index += 1 \n",
    "#             # print(index)\n",
    "#         except:\n",
    "#             pass\n",
    "    \n",
    "\n",
    "\n",
    "# print(good_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6be026-77ff-4a52-b2e3-d6bddb879c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804498ce-f67e-44c0-9883-7124788af1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove duplicates from list\n",
    "mylist = list(dict.fromkeys(good_list))\n",
    "print(len(mylist))\n",
    "\n",
    "## find the longest sequence from that particular IGHV subgroup\n",
    "res = max(mylist, key = len)\n",
    "print(res)\n",
    "print(len(res))\n",
    "\n",
    "# # ## introduce padding such that all sequences with same length \n",
    "for i in range(len(mylist)):\n",
    "    if len(mylist[i]) < 24:\n",
    "        print(mylist[i])\n",
    "        print(\"length is:\" + str(len(mylist[i])))\n",
    "        add_index = 24-len(mylist[i])\n",
    "        print(add_index)\n",
    "        mylist[i] = mylist[i].ljust(add_index+len(mylist[i]),'-')\n",
    "        print(\"after change\")\n",
    "        print(len(mylist[i]))\n",
    "        # time.sleep(100)\n",
    "    else:\n",
    "        mylist[i] = mylist[i]\n",
    "        \n",
    "print(mylist)\n",
    "mylist_df = pd.DataFrame(mylist)\n",
    "mylist_df.to_csv(\"viral_antigen_df_OC43.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6998ee52-5f6f-49bc-b29b-eb6d718a7297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8757bf-7ef2-4c33-860b-c5831b20a923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca980d40-51b5-4505-8300-8e3ce509b827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
